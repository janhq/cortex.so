---
title: Cortex.cpp
description: Cortex.cpp Architecture
slug: "cortex-cpp"
---

:::warning
ðŸš§ Cortex is currently under development. Our documentation outlines the intended behavior of Cortex, which may not yet be fully implemented in the codebase.
:::

Cortex.cpp is a stateless, C++ server that is 100% compatible with OpenAI API (stateless endpoints).

It includes a Drogon server, with request queues, model orchestration logic, and hardware telemetry, and more, for prod environments.

This guide walks you through how Cortex.CPP is designed, the codebase structure, and future plans.

## Usage

See [Quickstart](/docs/quickstart)

## Interface

## Architecture

## Code Structure

```md
â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ controllers/
â”‚ â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â”œâ”€â”€ ?engines/
â”‚ â”‚ â”‚ â”œâ”€â”€ llama.cpp
â”‚ â”‚ â”‚ â”œâ”€â”€ tensorrt-llm
â”‚ â”‚ â”‚ â””â”€â”€ ...
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”œâ”€â”€ CMakeLists.txt
â”‚ â”œâ”€â”€ config.json
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ docker-compose.yml
â”‚ â”œâ”€â”€ README.md
â”‚ â””â”€â”€ ...
```

`cortex-cpp` folder contains stateless implementations, most of which call into `cortex.llamacpp` and `cortex.tensorrt-llm`, depending on the engine at runtime.

Here you will find the implementations for stateless endpoints:

- `/chat/completion`
- `/audio`
- `/fine_tuning`
- `/embeddings`
- `/load_model`
- `/unload_model`

And core hardware and model management logic like CPU instruction set detection, and multiple model loading logic.

## Runtime

## Roadmap
